{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55526e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tensorflow.python.client import device_lib\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0530a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3989939004107434461\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(device_lib.list_local_devices())\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]=\"true\"\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only use the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPU\")\n",
    "  except RuntimeError as e:\n",
    "    # Visible devices must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fb9bf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_DataPathList(path=\"anno.csv\"):\n",
    "    f = open(path, mode=\"r\", encoding=\"UTF-8\")\n",
    "    tmp = f.readlines()\n",
    "    datalist = []\n",
    "    for dpath in tmp:\n",
    "        datalist.append(dpath.split(\",\")[0])\n",
    "    f.close()\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b51266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_Datalabel(path=\"anno.csv\"):\n",
    "    f = open(path, mode=\"r\", encoding=\"UTF-8\")\n",
    "    tmp = f.readlines()\n",
    "    datalist = []\n",
    "    \n",
    "    for dpath in tmp:\n",
    "        tmp2 = dpath.split(\",\")[1].replace(\"\\n\", \"\")\n",
    "        datalist.append([int(i) for i in tmp2])\n",
    "    return datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7efe6a95",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [1],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_Datalabel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdc0807",
   "metadata": {},
   "outputs": [],
   "source": [
    "datalist = return_DataPathList()\n",
    "data = [] # 読み込んだ座標データを格納する\n",
    "label = return_Datalabel()\n",
    "train_data = [] # 学習データを格納する\n",
    "test_data = [] #　テストデータを格納する\n",
    "train_label = [] # 学習ラベルを格納する\n",
    "test_label = [] # テストラベルを格納する\n",
    "tmp_data = 0 # 一時的に座標データを格納する\n",
    "max = 0\n",
    "for i in range(len(return_Datalabel())):\n",
    "    tmp_data = pd.read_csv(datalist[i], header=None).values\n",
    "\n",
    "    data.append(tmp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed708dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    if i%20 == 0:\n",
    "        test_data.append(data[i])\n",
    "        test_label.append(label[i])\n",
    "    else:\n",
    "        train_data.append(data[i])\n",
    "        train_label.append(label[i])\n",
    "train_data = np.array(train_data).astype(np.float32)\n",
    "test_data = np.array(test_data).astype(np.float32)\n",
    "train_label = np.array(train_label).astype(np.int64)\n",
    "test_label = np.array(test_label).astype(np.int64)\n",
    "train_data = np.expand_dims(train_data, -1)\n",
    "test_data = np.expand_dims(test_data, -1)\n",
    "test_label = keras.utils.to_categorical(test_label, 2)\n",
    "train_label = keras.utils.to_categorical(train_label, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca58714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 14\n"
     ]
    }
   ],
   "source": [
    "dim1 = np.array([[1]]*len(train_data)).astype(np.int64)\n",
    "dim2 = np.array([[1]]*len(test_data)).astype(np.int64)\n",
    "#print(dim)\n",
    "print(len(train_data[0]), len(train_data[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "771a7507",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9c98e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 13, 14, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None, 2), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "SHUFFLE_BUFFER_SIZE = 1000000\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55f7befb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Shogi-winner-model\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                                    Output Shape                                Param #          \n",
      "==============================================================================================================\n",
      " input (InputLayer)                              [(None, 13, 14)]                            0                \n",
      "                                                                                                              \n",
      " expand_dim (Reshape)                            (None, 14, 13, 1)                           0                \n",
      "                                                                                                              \n",
      " conv2d_2 (Conv2D)                               (None, 12, 11, 32)                          320              \n",
      "                                                                                                              \n",
      " max_pooling2d_2 (MaxPooling2D)                  (None, 6, 5, 32)                            0                \n",
      "                                                                                                              \n",
      " conv2d_3 (Conv2D)                               (None, 4, 3, 64)                            18496            \n",
      "                                                                                                              \n",
      " max_pooling2d_3 (MaxPooling2D)                  (None, 2, 1, 64)                            0                \n",
      "                                                                                                              \n",
      " flatten_1 (Flatten)                             (None, 128)                                 0                \n",
      "                                                                                                              \n",
      " dropout_1 (Dropout)                             (None, 128)                                 0                \n",
      "                                                                                                              \n",
      " dense_1 (Dense)                                 (None, 2)                                   258              \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 19,074\n",
      "Trainable params: 19,074\n",
      "Non-trainable params: 0\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
    "    \"\"\"Model similar to DeepSpeech2.\"\"\"\n",
    "    # Model's input\n",
    "    input_model = layers.Input((input_dim[0], input_dim[1]), name=\"input\")\n",
    "    # Expand the dimension to use 2D CNN.\n",
    "    x = layers.Reshape((-1, input_dim[0], 1), name=\"expand_dim\")(input_model)\n",
    "    x = layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    # Classification layer\n",
    "    output = layers.Dense(units=output_dim, activation=\"softmax\")(x)\n",
    "    # Model\n",
    "    model = keras.Model(input_model, output, name=\"Shogi-winner-model\")\n",
    "    # Optimizer\n",
    "    opt = keras.optimizers.Adam(learning_rate=1e-6)\n",
    "    # Compile the model and return\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model(\n",
    "    input_dim=[13,14],\n",
    "    output_dim=2,\n",
    "    rnn_units=512\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3fb501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
    "    # Iterate over the results and get back the text\n",
    "    output_text = []\n",
    "    for result in results:\n",
    "        result = tf.strings.reduce_join(num_to_char(result)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(result)\n",
    "    return output_text\n",
    "\n",
    "\n",
    "# A callback class to output a few transcriptions during training\n",
    "class CallbackEval(keras.callbacks.Callback):\n",
    "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def on_epoch_end(self, epoch: int, logs=None):\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for batch in self.dataset:\n",
    "            X, y = batch\n",
    "            batch_predictions = model.predict(X)\n",
    "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "            predictions.extend(batch_predictions)\n",
    "            for label in y:\n",
    "                label = (\n",
    "                    tf.strings.reduce_join(num_to_char(label)).numpy().decode(\"utf-8\")\n",
    "                )\n",
    "                targets.append(label)\n",
    "\n",
    "        for i in np.random.randint(0, len(predictions), 2):\n",
    "            print(f\"Target    : {targets[i]}\")\n",
    "            print(f\"Prediction: {predictions[i]}\")\n",
    "            print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "986b497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "tensorboard_callback = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55302eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.9532 - accuracy: 0.5108\n",
      "Epoch 2/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.8916 - accuracy: 0.5081\n",
      "Epoch 3/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.8446 - accuracy: 0.5154\n",
      "Epoch 4/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.8036 - accuracy: 0.5172\n",
      "Epoch 5/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.7790 - accuracy: 0.5192\n",
      "Epoch 6/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.7544 - accuracy: 0.5254\n",
      "Epoch 7/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.7410 - accuracy: 0.5276\n",
      "Epoch 8/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.7261 - accuracy: 0.5322\n",
      "Epoch 9/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.7160 - accuracy: 0.5392\n",
      "Epoch 10/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.7101 - accuracy: 0.5402\n",
      "Epoch 11/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.7021 - accuracy: 0.5435\n",
      "Epoch 12/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6965 - accuracy: 0.5481\n",
      "Epoch 13/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6929 - accuracy: 0.5511\n",
      "Epoch 14/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6892 - accuracy: 0.5543\n",
      "Epoch 15/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6870 - accuracy: 0.5578\n",
      "Epoch 16/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.6825 - accuracy: 0.5628\n",
      "Epoch 17/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6817 - accuracy: 0.5660\n",
      "Epoch 18/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6806 - accuracy: 0.5633\n",
      "Epoch 19/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6772 - accuracy: 0.5724\n",
      "Epoch 20/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6775 - accuracy: 0.5674\n",
      "Epoch 21/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.6753 - accuracy: 0.5747\n",
      "Epoch 22/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6738 - accuracy: 0.5758\n",
      "Epoch 23/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6725 - accuracy: 0.5784\n",
      "Epoch 24/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6722 - accuracy: 0.5771\n",
      "Epoch 25/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6708 - accuracy: 0.5795\n",
      "Epoch 26/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6694 - accuracy: 0.5854\n",
      "Epoch 27/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6696 - accuracy: 0.5819\n",
      "Epoch 28/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6682 - accuracy: 0.5842\n",
      "Epoch 29/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6685 - accuracy: 0.5851\n",
      "Epoch 30/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6666 - accuracy: 0.5856\n",
      "Epoch 31/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.6652 - accuracy: 0.5910\n",
      "Epoch 32/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6653 - accuracy: 0.5895\n",
      "Epoch 33/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6631 - accuracy: 0.5951\n",
      "Epoch 34/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6629 - accuracy: 0.5964\n",
      "Epoch 35/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6632 - accuracy: 0.5966\n",
      "Epoch 36/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6627 - accuracy: 0.5967\n",
      "Epoch 37/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.6610 - accuracy: 0.5984\n",
      "Epoch 38/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.6609 - accuracy: 0.5980\n",
      "Epoch 39/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6590 - accuracy: 0.6005\n",
      "Epoch 40/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.6597 - accuracy: 0.5970\n",
      "Epoch 41/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6574 - accuracy: 0.6074\n",
      "Epoch 42/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6581 - accuracy: 0.6034\n",
      "Epoch 43/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6576 - accuracy: 0.6030\n",
      "Epoch 44/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6570 - accuracy: 0.6037\n",
      "Epoch 45/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6555 - accuracy: 0.6073\n",
      "Epoch 46/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6565 - accuracy: 0.6054\n",
      "Epoch 47/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.6549 - accuracy: 0.6076\n",
      "Epoch 48/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6534 - accuracy: 0.6109\n",
      "Epoch 49/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6534 - accuracy: 0.6096\n",
      "Epoch 50/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6525 - accuracy: 0.6091\n",
      "Epoch 51/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6521 - accuracy: 0.6108\n",
      "Epoch 52/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6518 - accuracy: 0.6149\n",
      "Epoch 53/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6503 - accuracy: 0.6143\n",
      "Epoch 54/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6498 - accuracy: 0.6167\n",
      "Epoch 55/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6486 - accuracy: 0.6158\n",
      "Epoch 56/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6492 - accuracy: 0.6163\n",
      "Epoch 57/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6485 - accuracy: 0.6179\n",
      "Epoch 58/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6477 - accuracy: 0.6178\n",
      "Epoch 59/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6478 - accuracy: 0.6175\n",
      "Epoch 60/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6463 - accuracy: 0.6199\n",
      "Epoch 61/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6457 - accuracy: 0.6250\n",
      "Epoch 62/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6459 - accuracy: 0.6216\n",
      "Epoch 63/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6450 - accuracy: 0.6246\n",
      "Epoch 64/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6439 - accuracy: 0.6206\n",
      "Epoch 65/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6435 - accuracy: 0.6269\n",
      "Epoch 66/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6439 - accuracy: 0.6232\n",
      "Epoch 67/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6428 - accuracy: 0.6265\n",
      "Epoch 68/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6421 - accuracy: 0.6271\n",
      "Epoch 69/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6399 - accuracy: 0.6311\n",
      "Epoch 70/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6402 - accuracy: 0.6293\n",
      "Epoch 71/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6405 - accuracy: 0.6293\n",
      "Epoch 72/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6397 - accuracy: 0.6291\n",
      "Epoch 73/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6396 - accuracy: 0.6290\n",
      "Epoch 74/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6384 - accuracy: 0.6324\n",
      "Epoch 75/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6376 - accuracy: 0.6319\n",
      "Epoch 76/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6384 - accuracy: 0.6341\n",
      "Epoch 77/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.6369 - accuracy: 0.6346\n",
      "Epoch 78/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6375 - accuracy: 0.6358\n",
      "Epoch 79/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6358 - accuracy: 0.6357\n",
      "Epoch 80/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6357 - accuracy: 0.6353\n",
      "Epoch 81/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6364 - accuracy: 0.6354\n",
      "Epoch 82/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6358 - accuracy: 0.6346\n",
      "Epoch 83/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6338 - accuracy: 0.6399\n",
      "Epoch 84/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6328 - accuracy: 0.6408\n",
      "Epoch 85/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6327 - accuracy: 0.6397\n",
      "Epoch 86/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6324 - accuracy: 0.6429\n",
      "Epoch 87/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.6315 - accuracy: 0.6403\n",
      "Epoch 88/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6311 - accuracy: 0.6456\n",
      "Epoch 89/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6302 - accuracy: 0.6437\n",
      "Epoch 90/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6300 - accuracy: 0.6452\n",
      "Epoch 91/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.6294 - accuracy: 0.6468\n",
      "Epoch 92/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6288 - accuracy: 0.6487\n",
      "Epoch 93/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6288 - accuracy: 0.6445\n",
      "Epoch 94/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6278 - accuracy: 0.6480\n",
      "Epoch 95/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6280 - accuracy: 0.6476\n",
      "Epoch 96/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6280 - accuracy: 0.6488\n",
      "Epoch 97/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.6253 - accuracy: 0.6501\n",
      "Epoch 98/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6269 - accuracy: 0.6478\n",
      "Epoch 99/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6237 - accuracy: 0.6526\n",
      "Epoch 100/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6250 - accuracy: 0.6507\n",
      "Epoch 101/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6238 - accuracy: 0.6524\n",
      "Epoch 102/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6231 - accuracy: 0.6484\n",
      "Epoch 103/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6229 - accuracy: 0.6531\n",
      "Epoch 104/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6228 - accuracy: 0.6531\n",
      "Epoch 105/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6222 - accuracy: 0.6536\n",
      "Epoch 106/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6212 - accuracy: 0.6521\n",
      "Epoch 107/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6206 - accuracy: 0.6542\n",
      "Epoch 108/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6211 - accuracy: 0.6533\n",
      "Epoch 109/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6191 - accuracy: 0.6568\n",
      "Epoch 110/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6206 - accuracy: 0.6572\n",
      "Epoch 111/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6185 - accuracy: 0.6559\n",
      "Epoch 112/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.6191 - accuracy: 0.6591\n",
      "Epoch 113/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6194 - accuracy: 0.6556\n",
      "Epoch 114/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6176 - accuracy: 0.6615\n",
      "Epoch 115/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6174 - accuracy: 0.6598\n",
      "Epoch 116/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6162 - accuracy: 0.6610\n",
      "Epoch 117/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6164 - accuracy: 0.6607\n",
      "Epoch 118/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6160 - accuracy: 0.6612\n",
      "Epoch 119/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6159 - accuracy: 0.6605\n",
      "Epoch 120/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6142 - accuracy: 0.6651\n",
      "Epoch 121/1000\n",
      "3722/3722 [==============================] - 8s 2ms/step - loss: 0.6140 - accuracy: 0.6622\n",
      "Epoch 122/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6125 - accuracy: 0.6649\n",
      "Epoch 123/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6141 - accuracy: 0.6660\n",
      "Epoch 124/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6124 - accuracy: 0.6665\n",
      "Epoch 125/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.6117 - accuracy: 0.6680\n",
      "Epoch 126/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6118 - accuracy: 0.6673\n",
      "Epoch 127/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6111 - accuracy: 0.6640\n",
      "Epoch 128/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6111 - accuracy: 0.6663\n",
      "Epoch 129/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6097 - accuracy: 0.6692\n",
      "Epoch 130/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6088 - accuracy: 0.6699\n",
      "Epoch 131/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6087 - accuracy: 0.6668\n",
      "Epoch 132/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6088 - accuracy: 0.6656\n",
      "Epoch 133/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6083 - accuracy: 0.6694\n",
      "Epoch 134/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6077 - accuracy: 0.6694\n",
      "Epoch 135/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6068 - accuracy: 0.6724\n",
      "Epoch 136/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.6065 - accuracy: 0.6707\n",
      "Epoch 137/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6057 - accuracy: 0.6730\n",
      "Epoch 138/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6053 - accuracy: 0.6741\n",
      "Epoch 139/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.6053 - accuracy: 0.6727\n",
      "Epoch 140/1000\n",
      "3722/3722 [==============================] - 8s 2ms/step - loss: 0.6051 - accuracy: 0.6735\n",
      "Epoch 141/1000\n",
      "3722/3722 [==============================] - 8s 2ms/step - loss: 0.6043 - accuracy: 0.6719\n",
      "Epoch 142/1000\n",
      "3722/3722 [==============================] - 8s 2ms/step - loss: 0.6039 - accuracy: 0.6735\n",
      "Epoch 143/1000\n",
      "3722/3722 [==============================] - 8s 2ms/step - loss: 0.6020 - accuracy: 0.6740\n",
      "Epoch 144/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6025 - accuracy: 0.6759\n",
      "Epoch 145/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6029 - accuracy: 0.6790\n",
      "Epoch 146/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6013 - accuracy: 0.6771\n",
      "Epoch 147/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6019 - accuracy: 0.6737\n",
      "Epoch 148/1000\n",
      "3722/3722 [==============================] - 8s 2ms/step - loss: 0.6009 - accuracy: 0.6762\n",
      "Epoch 149/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6005 - accuracy: 0.6788\n",
      "Epoch 150/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.6014 - accuracy: 0.6737\n",
      "Epoch 151/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.6000 - accuracy: 0.6743\n",
      "Epoch 152/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5990 - accuracy: 0.6787\n",
      "Epoch 153/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5987 - accuracy: 0.6790\n",
      "Epoch 154/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5979 - accuracy: 0.6785\n",
      "Epoch 155/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5972 - accuracy: 0.6796\n",
      "Epoch 156/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.5970 - accuracy: 0.6818\n",
      "Epoch 157/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5945 - accuracy: 0.6814\n",
      "Epoch 158/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5951 - accuracy: 0.6844\n",
      "Epoch 159/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5947 - accuracy: 0.6830\n",
      "Epoch 160/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.5955 - accuracy: 0.6830\n",
      "Epoch 161/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5951 - accuracy: 0.6820\n",
      "Epoch 162/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5948 - accuracy: 0.6847\n",
      "Epoch 163/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5924 - accuracy: 0.6825\n",
      "Epoch 164/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5932 - accuracy: 0.6827\n",
      "Epoch 165/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5915 - accuracy: 0.6864\n",
      "Epoch 166/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5915 - accuracy: 0.6856\n",
      "Epoch 167/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5934 - accuracy: 0.6822\n",
      "Epoch 168/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.5891 - accuracy: 0.6886\n",
      "Epoch 169/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5898 - accuracy: 0.6877\n",
      "Epoch 170/1000\n",
      "3722/3722 [==============================] - 9s 2ms/step - loss: 0.5902 - accuracy: 0.6862\n",
      "Epoch 171/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5888 - accuracy: 0.6869\n",
      "Epoch 172/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5908 - accuracy: 0.6860\n",
      "Epoch 173/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5895 - accuracy: 0.6891\n",
      "Epoch 174/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.5872 - accuracy: 0.6881\n",
      "Epoch 175/1000\n",
      "3722/3722 [==============================] - 9s 3ms/step - loss: 0.5864 - accuracy: 0.6894\n",
      "Epoch 176/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5879 - accuracy: 0.6874\n",
      "Epoch 177/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5861 - accuracy: 0.6903\n",
      "Epoch 178/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5857 - accuracy: 0.6909\n",
      "Epoch 179/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5850 - accuracy: 0.6929\n",
      "Epoch 180/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5840 - accuracy: 0.6951\n",
      "Epoch 181/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5836 - accuracy: 0.6913\n",
      "Epoch 182/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5827 - accuracy: 0.6946\n",
      "Epoch 183/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5837 - accuracy: 0.6920\n",
      "Epoch 184/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5822 - accuracy: 0.6953\n",
      "Epoch 185/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5842 - accuracy: 0.6903\n",
      "Epoch 186/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5818 - accuracy: 0.6939\n",
      "Epoch 187/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5819 - accuracy: 0.6945\n",
      "Epoch 188/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5806 - accuracy: 0.6947\n",
      "Epoch 189/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5813 - accuracy: 0.6950\n",
      "Epoch 190/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5798 - accuracy: 0.6947\n",
      "Epoch 191/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5791 - accuracy: 0.6953\n",
      "Epoch 192/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5797 - accuracy: 0.6958\n",
      "Epoch 193/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5789 - accuracy: 0.6962\n",
      "Epoch 194/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5789 - accuracy: 0.6968\n",
      "Epoch 195/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5778 - accuracy: 0.6996\n",
      "Epoch 196/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5758 - accuracy: 0.7004\n",
      "Epoch 197/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5775 - accuracy: 0.6972\n",
      "Epoch 198/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5779 - accuracy: 0.6958\n",
      "Epoch 199/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5762 - accuracy: 0.7002\n",
      "Epoch 200/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5754 - accuracy: 0.7023\n",
      "Epoch 201/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5762 - accuracy: 0.6980\n",
      "Epoch 202/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5721 - accuracy: 0.7044\n",
      "Epoch 203/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5737 - accuracy: 0.7007\n",
      "Epoch 204/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5738 - accuracy: 0.7018\n",
      "Epoch 205/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5718 - accuracy: 0.7033\n",
      "Epoch 206/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5718 - accuracy: 0.7024\n",
      "Epoch 207/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5725 - accuracy: 0.7037\n",
      "Epoch 208/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5713 - accuracy: 0.7051\n",
      "Epoch 209/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5707 - accuracy: 0.7026\n",
      "Epoch 210/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5714 - accuracy: 0.7035\n",
      "Epoch 211/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5724 - accuracy: 0.7013\n",
      "Epoch 212/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5683 - accuracy: 0.7079\n",
      "Epoch 213/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5694 - accuracy: 0.7049\n",
      "Epoch 214/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5679 - accuracy: 0.7076\n",
      "Epoch 215/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5688 - accuracy: 0.7063\n",
      "Epoch 216/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5708 - accuracy: 0.7025\n",
      "Epoch 217/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5675 - accuracy: 0.7051\n",
      "Epoch 218/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5654 - accuracy: 0.7093\n",
      "Epoch 219/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5668 - accuracy: 0.7051\n",
      "Epoch 220/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5673 - accuracy: 0.7073\n",
      "Epoch 221/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5654 - accuracy: 0.7067\n",
      "Epoch 222/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5665 - accuracy: 0.7047\n",
      "Epoch 223/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5647 - accuracy: 0.7079\n",
      "Epoch 224/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5651 - accuracy: 0.7100\n",
      "Epoch 225/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5641 - accuracy: 0.7089\n",
      "Epoch 226/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5631 - accuracy: 0.7103\n",
      "Epoch 227/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5640 - accuracy: 0.7112\n",
      "Epoch 228/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5633 - accuracy: 0.7112\n",
      "Epoch 229/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5619 - accuracy: 0.7102\n",
      "Epoch 230/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5615 - accuracy: 0.7099\n",
      "Epoch 231/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5628 - accuracy: 0.7100\n",
      "Epoch 232/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5611 - accuracy: 0.7121\n",
      "Epoch 233/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5605 - accuracy: 0.7116\n",
      "Epoch 234/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5612 - accuracy: 0.7109\n",
      "Epoch 235/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5585 - accuracy: 0.7143\n",
      "Epoch 236/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5606 - accuracy: 0.7115\n",
      "Epoch 237/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5569 - accuracy: 0.7170\n",
      "Epoch 238/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5584 - accuracy: 0.7140\n",
      "Epoch 239/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5593 - accuracy: 0.7113\n",
      "Epoch 240/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5562 - accuracy: 0.7128\n",
      "Epoch 241/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5584 - accuracy: 0.7133\n",
      "Epoch 242/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5552 - accuracy: 0.7162\n",
      "Epoch 243/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5564 - accuracy: 0.7144\n",
      "Epoch 244/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5557 - accuracy: 0.7157\n",
      "Epoch 245/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5562 - accuracy: 0.7161\n",
      "Epoch 246/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5547 - accuracy: 0.7174\n",
      "Epoch 247/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5554 - accuracy: 0.7155\n",
      "Epoch 248/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5538 - accuracy: 0.7149\n",
      "Epoch 249/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5540 - accuracy: 0.7166\n",
      "Epoch 250/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5525 - accuracy: 0.7174\n",
      "Epoch 251/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5529 - accuracy: 0.7161\n",
      "Epoch 252/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5511 - accuracy: 0.7191\n",
      "Epoch 253/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5525 - accuracy: 0.7196\n",
      "Epoch 254/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5493 - accuracy: 0.7216\n",
      "Epoch 255/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5507 - accuracy: 0.7186\n",
      "Epoch 256/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5494 - accuracy: 0.7212\n",
      "Epoch 257/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5494 - accuracy: 0.7195\n",
      "Epoch 258/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5514 - accuracy: 0.7176\n",
      "Epoch 259/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5502 - accuracy: 0.7170\n",
      "Epoch 260/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5472 - accuracy: 0.7209\n",
      "Epoch 261/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5480 - accuracy: 0.7192\n",
      "Epoch 262/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5463 - accuracy: 0.7213\n",
      "Epoch 263/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5474 - accuracy: 0.7197\n",
      "Epoch 264/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5459 - accuracy: 0.7227\n",
      "Epoch 265/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5473 - accuracy: 0.7198\n",
      "Epoch 266/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5451 - accuracy: 0.7235\n",
      "Epoch 267/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5462 - accuracy: 0.7213\n",
      "Epoch 268/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5467 - accuracy: 0.7213\n",
      "Epoch 269/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5450 - accuracy: 0.7201\n",
      "Epoch 270/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5459 - accuracy: 0.7194\n",
      "Epoch 271/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5447 - accuracy: 0.7215\n",
      "Epoch 272/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5445 - accuracy: 0.7234\n",
      "Epoch 273/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5413 - accuracy: 0.7244\n",
      "Epoch 274/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5425 - accuracy: 0.7239\n",
      "Epoch 275/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5435 - accuracy: 0.7239\n",
      "Epoch 276/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5444 - accuracy: 0.7219\n",
      "Epoch 277/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5407 - accuracy: 0.7230\n",
      "Epoch 278/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5408 - accuracy: 0.7240\n",
      "Epoch 279/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5395 - accuracy: 0.7275\n",
      "Epoch 280/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5400 - accuracy: 0.7251\n",
      "Epoch 281/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5400 - accuracy: 0.7276\n",
      "Epoch 282/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5404 - accuracy: 0.7263\n",
      "Epoch 283/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5396 - accuracy: 0.7264\n",
      "Epoch 284/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5383 - accuracy: 0.7251\n",
      "Epoch 285/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5388 - accuracy: 0.7268\n",
      "Epoch 286/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5385 - accuracy: 0.7283\n",
      "Epoch 287/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5370 - accuracy: 0.7301\n",
      "Epoch 288/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.5350 - accuracy: 0.7311\n",
      "Epoch 289/1000\n",
      "3722/3722 [==============================] - 18s 5ms/step - loss: 0.5388 - accuracy: 0.7261\n",
      "Epoch 290/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5349 - accuracy: 0.7271\n",
      "Epoch 291/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.5343 - accuracy: 0.7291\n",
      "Epoch 292/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5351 - accuracy: 0.7305\n",
      "Epoch 293/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.5332 - accuracy: 0.7289\n",
      "Epoch 294/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5347 - accuracy: 0.7280\n",
      "Epoch 295/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5342 - accuracy: 0.7284\n",
      "Epoch 296/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5302 - accuracy: 0.7336\n",
      "Epoch 297/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5325 - accuracy: 0.7299\n",
      "Epoch 298/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5325 - accuracy: 0.7310\n",
      "Epoch 299/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5321 - accuracy: 0.7335\n",
      "Epoch 300/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5336 - accuracy: 0.7277\n",
      "Epoch 301/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5321 - accuracy: 0.7319\n",
      "Epoch 302/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5326 - accuracy: 0.7301\n",
      "Epoch 303/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5303 - accuracy: 0.7325\n",
      "Epoch 304/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5310 - accuracy: 0.7322\n",
      "Epoch 305/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5322 - accuracy: 0.7323\n",
      "Epoch 306/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5317 - accuracy: 0.7296\n",
      "Epoch 307/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5283 - accuracy: 0.7374\n",
      "Epoch 308/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5313 - accuracy: 0.7317\n",
      "Epoch 309/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5296 - accuracy: 0.7322\n",
      "Epoch 310/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5288 - accuracy: 0.7320\n",
      "Epoch 311/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5285 - accuracy: 0.7321\n",
      "Epoch 312/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5274 - accuracy: 0.7337\n",
      "Epoch 313/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5268 - accuracy: 0.7352\n",
      "Epoch 314/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5281 - accuracy: 0.7324\n",
      "Epoch 315/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5256 - accuracy: 0.7344\n",
      "Epoch 316/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5283 - accuracy: 0.7342\n",
      "Epoch 317/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5245 - accuracy: 0.7366\n",
      "Epoch 318/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5260 - accuracy: 0.7357\n",
      "Epoch 319/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5248 - accuracy: 0.7369\n",
      "Epoch 320/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.5258 - accuracy: 0.7347\n",
      "Epoch 321/1000\n",
      "3722/3722 [==============================] - 17s 5ms/step - loss: 0.5264 - accuracy: 0.7331\n",
      "Epoch 322/1000\n",
      "3722/3722 [==============================] - 19s 5ms/step - loss: 0.5235 - accuracy: 0.7360\n",
      "Epoch 323/1000\n",
      "3722/3722 [==============================] - 18s 5ms/step - loss: 0.5246 - accuracy: 0.7356\n",
      "Epoch 324/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.5244 - accuracy: 0.7372\n",
      "Epoch 325/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.5231 - accuracy: 0.7376\n",
      "Epoch 326/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.5247 - accuracy: 0.7340\n",
      "Epoch 327/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5222 - accuracy: 0.7365\n",
      "Epoch 328/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.5223 - accuracy: 0.7365\n",
      "Epoch 329/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.5194 - accuracy: 0.7409\n",
      "Epoch 330/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5210 - accuracy: 0.7381\n",
      "Epoch 331/1000\n",
      "3722/3722 [==============================] - 17s 4ms/step - loss: 0.5191 - accuracy: 0.7394\n",
      "Epoch 332/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.5197 - accuracy: 0.7381\n",
      "Epoch 333/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5196 - accuracy: 0.7388\n",
      "Epoch 334/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5187 - accuracy: 0.7388\n",
      "Epoch 335/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5201 - accuracy: 0.7374\n",
      "Epoch 336/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5199 - accuracy: 0.7383\n",
      "Epoch 337/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5176 - accuracy: 0.7406\n",
      "Epoch 338/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5159 - accuracy: 0.7409\n",
      "Epoch 339/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5169 - accuracy: 0.7385\n",
      "Epoch 340/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5176 - accuracy: 0.7398\n",
      "Epoch 341/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5177 - accuracy: 0.7414\n",
      "Epoch 342/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5175 - accuracy: 0.7402\n",
      "Epoch 343/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5148 - accuracy: 0.7430\n",
      "Epoch 344/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5137 - accuracy: 0.7427\n",
      "Epoch 345/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5157 - accuracy: 0.7416\n",
      "Epoch 346/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5153 - accuracy: 0.7428\n",
      "Epoch 347/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5139 - accuracy: 0.7440\n",
      "Epoch 348/1000\n",
      "3722/3722 [==============================] - 10s 3ms/step - loss: 0.5139 - accuracy: 0.7402\n",
      "Epoch 349/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5151 - accuracy: 0.7408\n",
      "Epoch 350/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5157 - accuracy: 0.7387\n",
      "Epoch 351/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5136 - accuracy: 0.7440\n",
      "Epoch 352/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5119 - accuracy: 0.7447\n",
      "Epoch 353/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5124 - accuracy: 0.7441\n",
      "Epoch 354/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5102 - accuracy: 0.7452\n",
      "Epoch 355/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5129 - accuracy: 0.7434\n",
      "Epoch 356/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5106 - accuracy: 0.7436\n",
      "Epoch 357/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5102 - accuracy: 0.7446\n",
      "Epoch 358/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5107 - accuracy: 0.7415\n",
      "Epoch 359/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5098 - accuracy: 0.7449\n",
      "Epoch 360/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5088 - accuracy: 0.7473\n",
      "Epoch 361/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5092 - accuracy: 0.7456\n",
      "Epoch 362/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5094 - accuracy: 0.7433\n",
      "Epoch 363/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5069 - accuracy: 0.7448\n",
      "Epoch 364/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5084 - accuracy: 0.7457\n",
      "Epoch 365/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5047 - accuracy: 0.7487\n",
      "Epoch 366/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5081 - accuracy: 0.7460\n",
      "Epoch 367/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5093 - accuracy: 0.7429\n",
      "Epoch 368/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5086 - accuracy: 0.7413\n",
      "Epoch 369/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.5060 - accuracy: 0.7469\n",
      "Epoch 370/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5067 - accuracy: 0.7489\n",
      "Epoch 371/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5055 - accuracy: 0.7472\n",
      "Epoch 372/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5044 - accuracy: 0.7467\n",
      "Epoch 373/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5050 - accuracy: 0.7464\n",
      "Epoch 374/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5062 - accuracy: 0.7459\n",
      "Epoch 375/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.5057 - accuracy: 0.7501\n",
      "Epoch 376/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5077 - accuracy: 0.7454\n",
      "Epoch 377/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5048 - accuracy: 0.7468\n",
      "Epoch 378/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.5034 - accuracy: 0.7499\n",
      "Epoch 379/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5006 - accuracy: 0.7516\n",
      "Epoch 380/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5031 - accuracy: 0.7485\n",
      "Epoch 381/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5022 - accuracy: 0.7483\n",
      "Epoch 382/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.5038 - accuracy: 0.7476\n",
      "Epoch 383/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.5020 - accuracy: 0.7493\n",
      "Epoch 384/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5001 - accuracy: 0.7520\n",
      "Epoch 385/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.5021 - accuracy: 0.7503\n",
      "Epoch 386/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.5012 - accuracy: 0.7514\n",
      "Epoch 387/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5027 - accuracy: 0.7476\n",
      "Epoch 388/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.5023 - accuracy: 0.7500\n",
      "Epoch 389/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.4991 - accuracy: 0.7528\n",
      "Epoch 390/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.4998 - accuracy: 0.7506\n",
      "Epoch 391/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4981 - accuracy: 0.7501\n",
      "Epoch 392/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.5000 - accuracy: 0.7498\n",
      "Epoch 393/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4990 - accuracy: 0.7488\n",
      "Epoch 394/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4970 - accuracy: 0.7542\n",
      "Epoch 395/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4966 - accuracy: 0.7504\n",
      "Epoch 396/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4985 - accuracy: 0.7498\n",
      "Epoch 397/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4979 - accuracy: 0.7526\n",
      "Epoch 398/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.4963 - accuracy: 0.7514\n",
      "Epoch 399/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4950 - accuracy: 0.7535\n",
      "Epoch 400/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.4964 - accuracy: 0.7515\n",
      "Epoch 401/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.4928 - accuracy: 0.7565\n",
      "Epoch 402/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4932 - accuracy: 0.7548\n",
      "Epoch 403/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4954 - accuracy: 0.7536\n",
      "Epoch 404/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4956 - accuracy: 0.7526\n",
      "Epoch 405/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.4936 - accuracy: 0.7529\n",
      "Epoch 406/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.4955 - accuracy: 0.7502\n",
      "Epoch 407/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4948 - accuracy: 0.7520\n",
      "Epoch 408/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4944 - accuracy: 0.7547\n",
      "Epoch 409/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4940 - accuracy: 0.7541\n",
      "Epoch 410/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.4920 - accuracy: 0.7551\n",
      "Epoch 411/1000\n",
      "3722/3722 [==============================] - 11s 3ms/step - loss: 0.4919 - accuracy: 0.7547\n",
      "Epoch 412/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.4910 - accuracy: 0.7552\n",
      "Epoch 413/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.4910 - accuracy: 0.7578\n",
      "Epoch 414/1000\n",
      "3722/3722 [==============================] - 12s 3ms/step - loss: 0.4908 - accuracy: 0.7568\n",
      "Epoch 415/1000\n",
      "3722/3722 [==============================] - 13s 3ms/step - loss: 0.4932 - accuracy: 0.7541\n",
      "Epoch 416/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4926 - accuracy: 0.7541\n",
      "Epoch 417/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4905 - accuracy: 0.7574\n",
      "Epoch 418/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4913 - accuracy: 0.7541\n",
      "Epoch 419/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4915 - accuracy: 0.7545\n",
      "Epoch 420/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4900 - accuracy: 0.7531\n",
      "Epoch 421/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.4912 - accuracy: 0.7548\n",
      "Epoch 422/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4885 - accuracy: 0.7590\n",
      "Epoch 423/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.4879 - accuracy: 0.7589\n",
      "Epoch 424/1000\n",
      "3722/3722 [==============================] - 13s 4ms/step - loss: 0.4914 - accuracy: 0.7561\n",
      "Epoch 425/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4892 - accuracy: 0.7563\n",
      "Epoch 426/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4871 - accuracy: 0.7607\n",
      "Epoch 427/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4857 - accuracy: 0.7608\n",
      "Epoch 428/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4869 - accuracy: 0.7586\n",
      "Epoch 429/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4870 - accuracy: 0.7569\n",
      "Epoch 430/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4867 - accuracy: 0.7583\n",
      "Epoch 431/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4873 - accuracy: 0.7584\n",
      "Epoch 432/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4864 - accuracy: 0.7590\n",
      "Epoch 433/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4862 - accuracy: 0.7599\n",
      "Epoch 434/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4864 - accuracy: 0.7590\n",
      "Epoch 435/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4848 - accuracy: 0.7607\n",
      "Epoch 436/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4849 - accuracy: 0.7596\n",
      "Epoch 437/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4858 - accuracy: 0.7581\n",
      "Epoch 438/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4830 - accuracy: 0.7589\n",
      "Epoch 439/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4834 - accuracy: 0.7601\n",
      "Epoch 440/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4823 - accuracy: 0.7620\n",
      "Epoch 441/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4821 - accuracy: 0.7593\n",
      "Epoch 442/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4833 - accuracy: 0.7611\n",
      "Epoch 443/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4838 - accuracy: 0.7589\n",
      "Epoch 444/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4819 - accuracy: 0.7599\n",
      "Epoch 445/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4823 - accuracy: 0.7610\n",
      "Epoch 446/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4824 - accuracy: 0.7595\n",
      "Epoch 447/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4812 - accuracy: 0.7636\n",
      "Epoch 448/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4813 - accuracy: 0.7597\n",
      "Epoch 449/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4790 - accuracy: 0.7632\n",
      "Epoch 450/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4802 - accuracy: 0.7637\n",
      "Epoch 451/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4803 - accuracy: 0.7635\n",
      "Epoch 452/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4809 - accuracy: 0.7628\n",
      "Epoch 453/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4796 - accuracy: 0.7597\n",
      "Epoch 454/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4807 - accuracy: 0.7620\n",
      "Epoch 455/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4788 - accuracy: 0.7636\n",
      "Epoch 456/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4777 - accuracy: 0.7617\n",
      "Epoch 457/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4775 - accuracy: 0.7625\n",
      "Epoch 458/1000\n",
      "3722/3722 [==============================] - 17s 5ms/step - loss: 0.4782 - accuracy: 0.7605\n",
      "Epoch 459/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4767 - accuracy: 0.7625\n",
      "Epoch 460/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4777 - accuracy: 0.7636\n",
      "Epoch 461/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4780 - accuracy: 0.7620\n",
      "Epoch 462/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4765 - accuracy: 0.7653\n",
      "Epoch 463/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4758 - accuracy: 0.7638\n",
      "Epoch 464/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4746 - accuracy: 0.7654\n",
      "Epoch 465/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4779 - accuracy: 0.7647\n",
      "Epoch 466/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4727 - accuracy: 0.7672\n",
      "Epoch 467/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4763 - accuracy: 0.7666\n",
      "Epoch 468/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4776 - accuracy: 0.7616\n",
      "Epoch 469/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4766 - accuracy: 0.7635\n",
      "Epoch 470/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4744 - accuracy: 0.7649\n",
      "Epoch 471/1000\n",
      "3722/3722 [==============================] - 17s 5ms/step - loss: 0.4750 - accuracy: 0.7630\n",
      "Epoch 472/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4750 - accuracy: 0.7646\n",
      "Epoch 473/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4747 - accuracy: 0.7638\n",
      "Epoch 474/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4732 - accuracy: 0.7647\n",
      "Epoch 475/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4727 - accuracy: 0.7667\n",
      "Epoch 476/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4730 - accuracy: 0.7640\n",
      "Epoch 477/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4700 - accuracy: 0.7674\n",
      "Epoch 478/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4706 - accuracy: 0.7688\n",
      "Epoch 479/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4725 - accuracy: 0.7675\n",
      "Epoch 480/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4719 - accuracy: 0.7674\n",
      "Epoch 481/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4736 - accuracy: 0.7642\n",
      "Epoch 482/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4715 - accuracy: 0.7671\n",
      "Epoch 483/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4694 - accuracy: 0.7675\n",
      "Epoch 484/1000\n",
      "3722/3722 [==============================] - 17s 5ms/step - loss: 0.4690 - accuracy: 0.7688\n",
      "Epoch 485/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4723 - accuracy: 0.7661\n",
      "Epoch 486/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4709 - accuracy: 0.7667\n",
      "Epoch 487/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4698 - accuracy: 0.7669\n",
      "Epoch 488/1000\n",
      "3722/3722 [==============================] - 14s 4ms/step - loss: 0.4709 - accuracy: 0.7670\n",
      "Epoch 489/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4705 - accuracy: 0.7650\n",
      "Epoch 490/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4701 - accuracy: 0.7674\n",
      "Epoch 491/1000\n",
      "3722/3722 [==============================] - 16s 4ms/step - loss: 0.4683 - accuracy: 0.7708\n",
      "Epoch 492/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4713 - accuracy: 0.7654\n",
      "Epoch 493/1000\n",
      "3722/3722 [==============================] - 15s 4ms/step - loss: 0.4663 - accuracy: 0.7722\n",
      "Epoch 494/1000\n",
      " 695/3722 [====>.........................] - ETA: 12s - loss: 0.4682 - accuracy: 0.7629"
     ]
    }
   ],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label))\n",
    "#test_dataset = test_dataset.batch()\n",
    "\"\"\"print(len(test_dataset))\n",
    "for batch in test_dataset:\n",
    "    X, y = batch\n",
    "    batch_predictions = model.predict(X)\n",
    "    batch_predictions = decode_batch_predictions(batch_predictions)\n",
    "    predictions.extend(batch_predictions)\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    print(f\"Target    : {targets[i]}\")\n",
    "    print(f\"Prediction: {predictions[i]}\")\n",
    "    print(\"-\" * 100)\"\"\"\n",
    "\n",
    "model.fit(train_dataset, epochs=1000, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea29b99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
